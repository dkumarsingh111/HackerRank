{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully with {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_exploration(data):\n",
    "    print(\"First 5 Rows:\\n\", data.head())\n",
    "    print(\"Data Info:\\n\", data.info())\n",
    "    print(\"Statistical Summary:\\n\", data.describe())\n",
    "    return data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(data, schema):\n",
    "    for col, dtype in schema.items():\n",
    "        if col in data.columns:\n",
    "            if not data[col].dtype == dtype:\n",
    "                print(f\"Invalid data type in column {col}. Expected {dtype}, got {data[col].dtype}.\")\n",
    "    print(\"Data validation completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handle_missing_values(data, strategy=\"mean\"):\n",
    "#     imputer = SimpleImputer(strategy=strategy)\n",
    "#     data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "#     return data_imputed\n",
    "\n",
    "def handle_missing_values(data, strategy=\"mean\"):\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    non_numeric_data = data.select_dtypes(exclude=[np.number])\n",
    "    \n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    numeric_data_imputed = pd.DataFrame(imputer.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "    \n",
    "    return pd.concat([numeric_data_imputed, non_numeric_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Manipulation (Feature Transformation, Deriving New Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def manipulate_data(data):\n",
    "#     # Example: Add a new column as a transformation of existing data\n",
    "#     data[\"new_feature\"] = data[\"feature1\"] * data[\"feature2\"]\n",
    "#     return data\n",
    "\n",
    "\n",
    "def manipulate_data(data):\n",
    "    if \"feature1\" in data.columns and \"feature2\" in data.columns:\n",
    "        data[\"new_feature\"] = data[\"feature1\"] * data[\"feature2\"]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Outlier Detection and Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def treat_outliers(data, threshold=3):\n",
    "#     z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
    "#     data_no_outliers = data[(z_scores < threshold).all(axis=1)]\n",
    "#     print(f\"Outliers removed. New data shape: {data_no_outliers.shape}\")\n",
    "#     return data_no_outliers\n",
    "\n",
    "\n",
    "def treat_outliers(data, threshold=3):\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    z_scores = np.abs(stats.zscore(numeric_data))\n",
    "    data_no_outliers = data[(z_scores < threshold).all(axis=1)]\n",
    "    print(f\"Outliers removed. New data shape: {data_no_outliers.shape}\")\n",
    "    return data_no_outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "    categorical_data = pd.DataFrame(encoder.fit_transform(data.select_dtypes(include=[\"object\"])),\n",
    "                                    columns=encoder.get_feature_names_out())\n",
    "    data = data.drop(columns=data.select_dtypes(include=[\"object\"]).columns)\n",
    "    data = pd.concat([data, categorical_data], axis=1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Transformation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_data(data, scaler_type=\"standard\"):\n",
    "#     scaler = StandardScaler() if scaler_type == \"standard\" else MinMaxScaler()\n",
    "#     data_transformed = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "#     return data_transformed\n",
    "\n",
    "\n",
    "def transform_data(data, scaler_type=\"standard\"):\n",
    "    scaler = StandardScaler() if scaler_type == \"standard\" else MinMaxScaler()\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    scaled_data = pd.DataFrame(scaler.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "    return pd.concat([scaled_data, data.select_dtypes(exclude=[np.number])], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_engineering(data):\n",
    "#     # Example: Dimensionality reduction using PCA\n",
    "#     pca = PCA(n_components=5)\n",
    "#     principal_components = pca.fit_transform(data)\n",
    "#     data_pca = pd.DataFrame(principal_components, columns=[f\"PCA_{i}\" for i in range(1, 6)])\n",
    "#     return pd.concat([data, data_pca], axis=1)\n",
    "\n",
    "\n",
    "def feature_engineering(data):\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    pca = PCA(n_components=min(5, numeric_data.shape[1]))\n",
    "    principal_components = pca.fit_transform(numeric_data)\n",
    "    data_pca = pd.DataFrame(principal_components, columns=[f\"PCA_{i}\" for i in range(1, principal_components.shape[1] + 1)])\n",
    "    return pd.concat([data, data_pca], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_data(data):\n",
    "    data_deduped = data.drop_duplicates()\n",
    "    print(f\"Duplicates removed. New data shape: {data_deduped.shape}\")\n",
    "    return data_deduped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(data, file_path):\n",
    "    try:\n",
    "        data.to_csv(file_path, index=False)\n",
    "        print(f\"Data exported successfully to {file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Error Handling and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='data_cleaning.log', level=logging.INFO)\n",
    "\n",
    "def log_and_handle_errors(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {e}\")\n",
    "            print(f\"Error in {func.__name__}: {e}\")\n",
    "            return None\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_data = log_and_handle_errors(ingest_data)\n",
    "initial_exploration = log_and_handle_errors(initial_exploration)\n",
    "validate_data = log_and_handle_errors(validate_data)\n",
    "handle_missing_values = log_and_handle_errors(handle_missing_values)\n",
    "manipulate_data = log_and_handle_errors(manipulate_data)\n",
    "treat_outliers = log_and_handle_errors(treat_outliers)\n",
    "encode_data = log_and_handle_errors(encode_data)\n",
    "transform_data = log_and_handle_errors(transform_data)\n",
    "feature_engineering = log_and_handle_errors(feature_engineering)\n",
    "deduplicate_data = log_and_handle_errors(deduplicate_data)\n",
    "export_data = log_and_handle_errors(export_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_pipeline(file_path, schema, export_path):\n",
    "    data = ingest_data(file_path)\n",
    "    if data is None:\n",
    "        return\n",
    "    \n",
    "    initial_exploration(data)\n",
    "    validate_data(data, schema)\n",
    "    \n",
    "    data = handle_missing_values(data)\n",
    "    data = manipulate_data(data)\n",
    "    data = treat_outliers(data)\n",
    "    data = encode_data(data)\n",
    "    data = transform_data(data, scaler_type=\"standard\")\n",
    "    data = feature_engineering(data)\n",
    "    data = deduplicate_data(data)\n",
    "    \n",
    "    export_data(data, export_path)\n",
    "    print(\"Data cleaning pipeline completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully with 55500 rows and 15 columns.\n",
      "First 5 Rows:\n",
      "             Name  Age  Gender Blood Type Medical Condition Date of Admission  \\\n",
      "0  Bobby JacksOn   30    Male         B-            Cancer        2024-01-31   \n",
      "1   LesLie TErRy   62    Male         A+           Obesity        2019-08-20   \n",
      "2    DaNnY sMitH   76  Female         A-           Obesity        2022-09-22   \n",
      "3   andrEw waTtS   28  Female         O+          Diabetes        2020-11-18   \n",
      "4  adrIENNE bEll   43  Female        AB+            Cancer        2022-09-19   \n",
      "\n",
      "             Doctor                    Hospital Insurance Provider  \\\n",
      "0     Matthew Smith             Sons and Miller         Blue Cross   \n",
      "1   Samantha Davies                     Kim Inc           Medicare   \n",
      "2  Tiffany Mitchell                    Cook PLC              Aetna   \n",
      "3       Kevin Wells  Hernandez Rogers and Vang,           Medicare   \n",
      "4    Kathleen Hanna                 White-White              Aetna   \n",
      "\n",
      "   Billing Amount  Room Number Admission Type Discharge Date   Medication  \\\n",
      "0    18856.281306          328         Urgent     2024-02-02  Paracetamol   \n",
      "1    33643.327287          265      Emergency     2019-08-26    Ibuprofen   \n",
      "2    27955.096079          205      Emergency     2022-10-07      Aspirin   \n",
      "3    37909.782410          450       Elective     2020-12-18    Ibuprofen   \n",
      "4    14238.317814          458         Urgent     2022-10-09   Penicillin   \n",
      "\n",
      "   Test Results  \n",
      "0        Normal  \n",
      "1  Inconclusive  \n",
      "2        Normal  \n",
      "3      Abnormal  \n",
      "4      Abnormal  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55500 entries, 0 to 55499\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Name                55500 non-null  object \n",
      " 1   Age                 55500 non-null  int64  \n",
      " 2   Gender              55500 non-null  object \n",
      " 3   Blood Type          55500 non-null  object \n",
      " 4   Medical Condition   55500 non-null  object \n",
      " 5   Date of Admission   55500 non-null  object \n",
      " 6   Doctor              55500 non-null  object \n",
      " 7   Hospital            55500 non-null  object \n",
      " 8   Insurance Provider  55500 non-null  object \n",
      " 9   Billing Amount      55500 non-null  float64\n",
      " 10  Room Number         55500 non-null  int64  \n",
      " 11  Admission Type      55500 non-null  object \n",
      " 12  Discharge Date      55500 non-null  object \n",
      " 13  Medication          55500 non-null  object \n",
      " 14  Test Results        55500 non-null  object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 6.4+ MB\n",
      "Data Info:\n",
      " None\n",
      "Statistical Summary:\n",
      "                 Age  Billing Amount   Room Number\n",
      "count  55500.000000    55500.000000  55500.000000\n",
      "mean      51.539459    25539.316097    301.134829\n",
      "std       19.602454    14211.454431    115.243069\n",
      "min       13.000000    -2008.492140    101.000000\n",
      "25%       35.000000    13241.224652    202.000000\n",
      "50%       52.000000    25538.069376    302.000000\n",
      "75%       68.000000    37820.508436    401.000000\n",
      "max       89.000000    52764.276736    500.000000\n",
      "Data validation completed.\n",
      "Outliers removed. New data shape: (55500, 15)\n",
      "Error in encode_data: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n",
      "Error in transform_data: 'NoneType' object has no attribute 'select_dtypes'\n",
      "Error in feature_engineering: 'NoneType' object has no attribute 'select_dtypes'\n",
      "Error in deduplicate_data: 'NoneType' object has no attribute 'drop_duplicates'\n",
      "Error exporting data: 'NoneType' object has no attribute 'to_csv'\n",
      "Data cleaning pipeline completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# schema = {\n",
    "#     \"feature1\": \"float64\",\n",
    "#     \"feature2\": \"int64\",\n",
    "#     \"category_feature\": \"object\"\n",
    "# }\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'Name': 'object',\n",
    "    'Age': 'int64',\n",
    "    'Gender': 'object',\n",
    "    'Blood Type': 'object',\n",
    "    'Medical Condition': 'object',\n",
    "    'Date of Admission': 'object',\n",
    "    'Doctor': 'object',\n",
    "    'Hospital': 'object',\n",
    "    'Insurance Provider': 'object',\n",
    "    'Billing Amount': 'float64',\n",
    "    'Room Number': 'int64',\n",
    "    'Admission Type': 'object',\n",
    "    'Discharge Date': 'object',\n",
    "    'Medication': 'object',\n",
    "    'Test Results': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "data_cleaning_pipeline(\"healthcare_dataset_raw.csv\", schema, \"cleaned_healthcare_dataset.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
